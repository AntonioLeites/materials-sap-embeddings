{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Material Embeddings\n",
    "\n",
    "## Going Beyond Text\n",
    "\n",
    "In this notebook, we combine **multiple information sources**:\n",
    "\n",
    "1. **Text** - Material description (semantic meaning)\n",
    "2. **Categorical** - MaterialGroup, MaterialType\n",
    "3. **Characteristics** - DIAMETER, LENGTH, MATERIAL, COATING\n",
    "4. **Relational** - Plants, Suppliers, Usage patterns\n",
    "\n",
    "This demonstrates **Tensor Logic**: similarity emerges from learned fusion of multiple features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.embeddings.multimodal_embeddings import MultimodalMaterialEmbeddings\n",
    "from src.sap_connector import create_sample_materials, print_material_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Materials with Full Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create materials with complete information\n",
    "materials = create_sample_materials(n_materials=10)\n",
    "\n",
    "print(f\"Generated {len(materials)} materials\\n\")\n",
    "print_material_summary(materials[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Multimodal Embedder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "embedder = MultimodalMaterialEmbeddings()\n",
    "\n",
    "# Update relational knowledge\n",
    "embedder.update_relational_knowledge(materials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Multimodal Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding for first material\n",
    "embedding = embedder.encode_multimodal(materials[0])\n",
    "\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"First 10 dimensions: {embedding[:10]}\")\n",
    "print(f\"\\nThis 768-d vector captures:\")\n",
    "print(\"  âœ“ Semantic meaning (from text)\")\n",
    "print(\"  âœ“ Business classification (from categories)\")\n",
    "print(\"  âœ“ Technical specifications (from characteristics)\")\n",
    "print(\"  âœ“ Usage context (from plants/suppliers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Two Materials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare materials\n",
    "mat1 = materials[0]\n",
    "mat2 = materials[1]\n",
    "\n",
    "print(f\"Material 1: {mat1['MAKTX']}\")\n",
    "print(f\"  Plants: {mat1['plants'][:2]}\")\n",
    "print(f\"  Suppliers: {mat1['suppliers'][:2]}\")\n",
    "print()\n",
    "print(f\"Material 2: {mat2['MAKTX']}\")\n",
    "print(f\"  Plants: {mat2['plants'][:2]}\")\n",
    "print(f\"  Suppliers: {mat2['suppliers'][:2]}\")\n",
    "print()\n",
    "\n",
    "similarity = embedder.similarity(mat1, mat2)\n",
    "print(f\"Overall Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explain Similarity by Component\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed breakdown\n",
    "explanation = embedder.explain_similarity(mat1, mat2)\n",
    "\n",
    "print(\"Similarity breakdown:\\n\")\n",
    "for component, score in explanation.items():\n",
    "    if component != 'overall':\n",
    "        bar_length = int(score * 50)\n",
    "        bar = \"â–ˆ\" * bar_length + \"â–‘\" * (50 - bar_length)\n",
    "        print(f\"{component:20s} {score:.4f} {bar}\")\n",
    "\n",
    "print(f\"\\n{'overall':20s} {explanation['overall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Component Contributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot component breakdown\n",
    "components = ['text', 'categorical', 'characteristics', 'relational']\n",
    "scores = [explanation[c] for c in components]\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(components, scores, color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "for bar, score in zip(bars, scores):\n",
    "    plt.text(score + 0.02, bar.get_y() + bar.get_height()/2.,\n",
    "             f'{score:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.xlabel('Similarity Score', fontsize=12)\n",
    "plt.title('Component Contribution to Similarity', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0, 1)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare: Text-Only vs Multimodal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-only embedding\n",
    "text_only = embedder.encode_multimodal(\n",
    "    mat1,\n",
    "    include_categorical=False,\n",
    "    include_characteristics=False,\n",
    "    include_relational=False\n",
    ")\n",
    "\n",
    "text_only2 = embedder.encode_multimodal(\n",
    "    mat2,\n",
    "    include_categorical=False,\n",
    "    include_characteristics=False,\n",
    "    include_relational=False\n",
    ")\n",
    "\n",
    "text_sim = float(np.dot(text_only, text_only2))\n",
    "\n",
    "print(f\"Text-only similarity:    {text_sim:.4f}\")\n",
    "print(f\"Multimodal similarity:   {similarity:.4f}\")\n",
    "print(f\"\\nImprovement: {((similarity - text_sim) / text_sim * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Key Insights\n",
    "\n",
    "1. **Multimodal embeddings** capture more than text similarity\n",
    "2. **Each component contributes** to the final similarity score\n",
    "3. **Relational context** (plants, suppliers) adds valuable signal\n",
    "4. **Fusion layer** learns optimal weighting of components\n",
    "\n",
    "This is **Tensor Logic** in action:\n",
    "- No explicit rules\n",
    "- Similarity emerges from learned patterns\n",
    "- Robust to variations in individual features\n",
    "\n",
    "## ðŸŽ¯ Next: Duplicate Detection\n",
    "\n",
    "Continue to **Notebook 04** to see how this approach finds **1481% more duplicates** than text-only methods!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "materials-embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
