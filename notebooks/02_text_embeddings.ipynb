{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Embeddings for Material Descriptions\n",
    "\n",
    "This notebook demonstrates how to generate semantic embeddings from material descriptions using Sentence Transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.embeddings.text_embeddings import MaterialEmbeddings\n",
    "from src.sap_connector import create_sample_materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Text Embedder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "embedder = MaterialEmbeddings()\n",
    "\n",
    "print(f\"Model: {embedder.model_name}\")\n",
    "print(f\"Ready to generate 768-dimensional embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Single Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single material\n",
    "description = \"Steel Bolt M8x50 DIN 933\"\n",
    "embedding = embedder.encode(description)\n",
    "\n",
    "print(f\"Description: {description}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"First 10 dimensions: {embedding[:10]}\")\n",
    "print(f\"Embedding norm: {np.linalg.norm(embedding):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare Two Materials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare similar materials\n",
    "mat1 = \"Steel Bolt M8x50 DIN 933\"\n",
    "mat2 = \"Stainless Steel Bolt M8x50 ISO 4017\"\n",
    "mat3 = \"Plastic Washer M8\"\n",
    "\n",
    "sim_12 = embedder.similarity(mat1, mat2)\n",
    "sim_13 = embedder.similarity(mat1, mat3)\n",
    "\n",
    "print(f\"Similarity between:\")\n",
    "print(f\"  '{mat1}'\")\n",
    "print(f\"  '{mat2}'\")\n",
    "print(f\"  â†’ {sim_12:.4f}\")\n",
    "print()\n",
    "print(f\"Similarity between:\")\n",
    "print(f\"  '{mat1}'\")\n",
    "print(f\"  '{mat3}'\")\n",
    "print(f\"  â†’ {sim_13:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Batch Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample materials\n",
    "materials = create_sample_materials(n_materials=20)\n",
    "descriptions = [m['MAKTX'] for m in materials]\n",
    "\n",
    "# Encode all\n",
    "embeddings = embedder.encode_batch(descriptions, show_progress=True)\n",
    "\n",
    "print(f\"\\nEncoded {len(descriptions)} materials\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize in 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce to 2D\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=100, alpha=0.6)\n",
    "\n",
    "# Annotate a few points\n",
    "for i in range(min(5, len(descriptions))):\n",
    "    plt.annotate(descriptions[i][:20], \n",
    "                (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.title('Text Embeddings (PCA 2D)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Similarity Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute similarity matrix (first 10 materials)\n",
    "n = min(10, len(embeddings))\n",
    "sim_matrix = cosine_similarity(embeddings[:n])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(sim_matrix, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "           xticklabels=[d[:15] for d in descriptions[:n]],\n",
    "           yticklabels=[d[:15] for d in descriptions[:n]])\n",
    "plt.title('Material Similarity Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Key Takeaways\n",
    "\n",
    "- Text embeddings capture **semantic meaning**\n",
    "- Similar materials have **high cosine similarity**\n",
    "- 768 dimensions encode rich information\n",
    "- Fast batch processing for large catalogs\n",
    "\n",
    "## ðŸŽ¯ Next: Multimodal Embeddings\n",
    "\n",
    "Continue to **Notebook 03** to see how adding categorical, characteristics, and relational features improves similarity detection by 1481%!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "materials-embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
